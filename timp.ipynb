{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0996028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import collections\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36db2ff",
   "metadata": {},
   "source": [
    "## Reading in AHRQ SDOH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c36deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/sdoh_2020_tract_1_0.xlsx'\n",
    "dfs = pd.read_excel(\n",
    "        path,\n",
    "        sheet_name = None,\n",
    "        dtype = str,\n",
    "        na_filter = False,\n",
    "        nrows = 1000,\n",
    ")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(name)\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        display(df.head())\n",
    "\n",
    "layout_df = dfs['Layout']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b7ac0",
   "metadata": {},
   "source": [
    "See what columns are not numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scope():\n",
    "    nonnumerics = []\n",
    "    for name, row in layout_df.iterrows():\n",
    "        if row['type'] != 'num':\n",
    "            nonnumerics.append(name)\n",
    "\n",
    "    for name in nonnumerics:\n",
    "        print(f'        {name!r}: str,')\n",
    "\n",
    "scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d731e",
   "metadata": {},
   "source": [
    "Read the entire file this time and default all columns to having float values with some exceptions. Takes around 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79703359",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#importing pandas as pd \n",
    "import pandas as pd \n",
    "\n",
    "# Read and store content \n",
    "# of an excel file \n",
    "read_file = pd.read_excel (\"../data/ahrq/sdoh_2020_tract_1_0.xlsx\", sheet_name=\"Data\") \n",
    "\n",
    "# Write the dataframe object \n",
    "# into csv file \n",
    "read_file.to_csv (\"../data/ahrq/sdoh_2020_tract_1_0_data.csv\", \n",
    "\t\t\t\tindex = None, \n",
    "\t\t\t\theader=True) \n",
    "\t\n",
    "# read csv file and convert \n",
    "# into a dataframe object \n",
    "df = pd.DataFrame(pd.read_csv(\"../data/ahrq/sdoh_2020_tract_1_0_data.csv\")) \n",
    "\n",
    "# show the dataframe \n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_df = pd.read_excel(\n",
    "    path,\n",
    "    sheet_name = (\n",
    "        'Data'\n",
    "    ),\n",
    "    dtype = collections.defaultdict(lambda: float) | {\n",
    "        'TRACTFIPS': str,\n",
    "        'COUNTYFIPS': str,\n",
    "        'STATEFIPS': str,\n",
    "        'STATE': str,\n",
    "        'COUNTY': str,\n",
    "        'REGION': str,\n",
    "        'CEN_AIAN_NH_IND': str,\n",
    "    },\n",
    "    na_filter = True,\n",
    "    na_values=['', ' '],\n",
    ")\n",
    "'''\n",
    "\n",
    "path = 'data/sdoh_2020_tract_1_0_data.csv'\n",
    "data_df = pd.read_csv(\n",
    "    path,\n",
    "    dtype = collections.defaultdict(lambda: float) | {\n",
    "        'TRACTFIPS': str,\n",
    "        'COUNTYFIPS': str,\n",
    "        'STATEFIPS': str,\n",
    "        'STATE': str,\n",
    "        'COUNTY': str,\n",
    "        'REGION': str,\n",
    "        'CEN_AIAN_NH_IND': str,\n",
    "    },\n",
    "    na_filter = True,\n",
    "    na_values=['', ' '],\n",
    ")\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display info on the data columns\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c905615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate statistics on the data columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88263ac7",
   "metadata": {},
   "source": [
    "## Merge with TN census tract shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file('data/tl_2020_47_tract/tl_2020_47_tract.shp')\n",
    "display(shapefile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After performing the merge\n",
    "merged = data_df.merge(shapefile[['GEOID', 'geometry']], left_on='TRACTFIPS', right_on='GEOID', how='left')\n",
    "\n",
    "# Reorder the columns to move 'GEOID' and 'geometry' to the front\n",
    "columns = ['GEOID', 'geometry'] + [col for col in merged.columns if col not in ['GEOID', 'geometry']]\n",
    "merged = merged[columns]\n",
    "\n",
    "gdf = gpd.GeoDataFrame(merged, geometry='geometry')\n",
    "tennessee_gdf = gdf[gdf[\"GEOID\"].astype(str).str.startswith('47')]\n",
    "display(tennessee_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83379227",
   "metadata": {},
   "source": [
    "Filter down to the columns I initially think will be useful to career prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tennessee_gdf = tennessee_gdf[\n",
    "    [\n",
    "        'GEOID',\n",
    "        'geometry',\n",
    "        'STATE',\n",
    "        'COUNTY',\n",
    "        'COUNTYFIPS',\n",
    "        'CEN_POPDENSITY_TRACT',\n",
    "\n",
    "        'ACS_MEDIAN_AGE',\n",
    "        'ACS_PCT_AGE_18_29',\n",
    "        'ACS_PCT_AGE_30_44', \n",
    "        'ACS_PCT_AGE_45_64',\n",
    "\n",
    "        'ACS_PCT_LT_HS',\n",
    "        'ACS_PCT_HS_GRADUATE',\n",
    "        'ACS_PCT_COLLEGE_ASSOCIATE_DGR',   \n",
    "        'ACS_PCT_BACHELOR_DGR',\n",
    "        'ACS_PCT_GRADUATE_DGR',\n",
    "        'ACS_PCT_POSTHS_ED',\n",
    "        \n",
    "        'ACS_MEDIAN_HH_INC',\n",
    "        'ACS_MEDIAN_INC_F',\n",
    "        'ACS_MEDIAN_INC_M',\n",
    "        \n",
    "        'ACS_PCT_EMPLOYED',\n",
    "        'ACS_PCT_NOT_LABOR',\n",
    "        'ACS_PCT_UNEMPLOY',\n",
    "\n",
    "        'ACS_PCT_ADMIN',\n",
    "        'ACS_PCT_ARMED_FORCES',\n",
    "        'ACS_PCT_ART',\n",
    "        'ACS_PCT_CONSTRUCT',\n",
    "        'ACS_PCT_EDUC',\n",
    "        'ACS_PCT_FINANCE',\n",
    "        'ACS_PCT_GOVT',\n",
    "        'ACS_PCT_INFORM',\n",
    "        'ACS_PCT_MANUFACT',\n",
    "        'ACS_PCT_NATURE',\n",
    "        'ACS_PCT_PROFESS',\n",
    "        'ACS_PCT_RETAIL',\n",
    "        'ACS_PCT_TRANSPORT',\n",
    "        'ACS_PCT_WHOLESALE',\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(filtered_tennessee_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tennessee_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tennessee_gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70376050",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = filtered_tennessee_gdf.shape\n",
    "print(old_shape)\n",
    "for i in filtered_tennessee_gdf:\n",
    "    print(f\"{i}: {filtered_tennessee_gdf[i].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ee204",
   "metadata": {},
   "source": [
    "Honestly it's not a lot of data to lose. Let's just drop the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cace4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_filtered_tennessee_gdf = filtered_tennessee_gdf.dropna()\n",
    "deleted_rows = old_shape[0] - clean_filtered_tennessee_gdf.shape[0]\n",
    "print(f\"Old shape: {old_shape}\")\n",
    "print(f\"New shape: {clean_filtered_tennessee_gdf.shape}\")\n",
    "print(f\"Deleted rows: {deleted_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a659fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, f1_score, accuracy_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ac245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_filtered_tennessee_gdf.copy()\n",
    "\n",
    "# Drop geometry column for machine learning purposes\n",
    "df_ml = df.drop(columns=['geometry'])\n",
    "\n",
    "\n",
    "## Create career-specific features\n",
    "# Create dictionary mappings for career fields to relevant features\n",
    "career_field_features = {\n",
    "    'armed forces' : ['ACS_PCT_ARMED_FORCES'],\n",
    "    'arts (entertainment, recreation, accommodation, and food services)' : ['ACS_PCT_ART'],\n",
    "    'construction' : ['ACS_PCT_CONSTRUCT'],\n",
    "    'educational services (healthcare, social assistance)' : ['ACS_PCT_EDUC'],\n",
    "    'finance (insurance, real estate, rental/leasing)' : ['ACS_PCT_FINANCE'],\n",
    "    'government' : ['ACS_PCT_GOVT'],\n",
    "    'informaton services' : ['ACS_PCT_INFORM'],\n",
    "    'manufacturing' : ['ACS_PCT_MANUFACT'],\n",
    "    'nature (agriculature, forestry, fishing, hunting, mining)' : ['ACS_PCT_NATURE'],\n",
    "    'professional (scientific, management, administrative, and waste management)' : ['ACS_PCT_PROFESS'],\n",
    "    'public administration' : ['ACS_PCT_ADMIN'],\n",
    "    'retail' : ['ACS_PCT_RETAIL'],\n",
    "    'transportation (warehousing, utilities)' : ['ACS_PCT_TRANSPORT'],\n",
    "    'wholesale' : ['ACS_PCT_WHOLESALE']\n",
    "}\n",
    "\n",
    "# Create education level features\n",
    "education_levels = {\n",
    "    'less_than_high_school': ['ACS_PCT_LT_HS'],\n",
    "    'high_school': ['ACS_PCT_HS_GRADUATE'],\n",
    "    'some_college/associates': ['ACS_PCT_COLLEGE_ASSOCIATE_DGR'],\n",
    "    'bachelors': ['ACS_PCT_BACHELOR_DGR'],\n",
    "    'masters/doctorate': ['ACS_PCT_GRADUATE_DGR'],   \n",
    "    'postsecondary': ['ACS_PCT_POSTHS_ED']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b875a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_career_suitability_model():\n",
    "    \"\"\"\n",
    "    Trains a random forest model to predict career suitability scores for counties.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (trained model, list of feature names used)\n",
    "    \"\"\"\n",
    "    # Define features and target for each county\n",
    "    feature_vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    # Define career weights for creating a composite target score\n",
    "    career_weights = {\n",
    "        career: i/len(career_field_features) \n",
    "        for i, career in enumerate(career_field_features.keys(), 1)\n",
    "    }\n",
    "    \n",
    "    # Loop through each county\n",
    "    for _, county in clean_filtered_tennessee_gdf.iterrows():\n",
    "        # Extract features that don't leak information about our target\n",
    "        features = [\n",
    "            county['ACS_MEDIAN_HH_INC'],\n",
    "            county['CEN_POPDENSITY_TRACT'] if 'CEN_POPDENSITY_TRACT' in county else 0,\n",
    "            county['ACS_MEDIAN_AGE'] if 'ACS_MEDIAN_AGE' in county else 0,\n",
    "            # Add education level features\n",
    "            county['ACS_PCT_LT_HS'] if 'ACS_PCT_LT_HS' in county else 0,\n",
    "            county['ACS_PCT_HS_GRADUATE'] if 'ACS_PCT_HS_GRADUATE' in county else 0,\n",
    "            county['ACS_PCT_COLLEGE_ASSOCIATE_DGR'] if 'ACS_PCT_COLLEGE_ASSOCIATE_DGR' in county else 0,\n",
    "            county['ACS_PCT_BACHELOR_DGR'] if 'ACS_PCT_BACHELOR_DGR' in county else 0,\n",
    "            county['ACS_PCT_GRADUATE_DGR'] if 'ACS_PCT_GRADUATE_DGR' in county else 0,\n",
    "            county['ACS_PCT_POSTHS_ED'] if 'ACS_PCT_POSTHS_ED' in county else 0,\n",
    "        ]\n",
    "        # Add career-specific features - but don't include the actual target columns\n",
    "        for career, columns in career_field_features.items():\n",
    "            # Use only the first feature from each career field to avoid data leakage\n",
    "            # and potential collinearity issues\n",
    "            if columns and columns[0] in county:\n",
    "                features.append(county[columns[0]])\n",
    "            else:\n",
    "                features.append(0)  # Default value if column doesn't exist\n",
    "        \n",
    "        feature_vectors.append(features)\n",
    "        \n",
    "        # Create a composite target that represents overall career suitability\n",
    "        # This is better than using employment rate directly as it creates a more\n",
    "        # meaningful target that combines multiple factors\n",
    "        target_score = 0.5 * county['ACS_PCT_EMPLOYED']  # Base score from employment\n",
    "        \n",
    "        # Add career-specific components to the target\n",
    "        for career, columns in career_field_features.items():\n",
    "            if columns and columns[0] in county:\n",
    "                # Weight each career field differently to create variety in predictions\n",
    "                target_score += career_weights[career] * county[columns[0]] * 0.5\n",
    "                \n",
    "        labels.append(target_score)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(feature_vectors)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    test_size = 0.3\n",
    "    x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Feature names for interpretability\n",
    "    feature_names = [\n",
    "        'ACS_MEDIAN_HH_INC', \n",
    "        'CEN_POPDENSITY_TRACT', \n",
    "        'ACS_MEDIAN_AGE',\n",
    "        'ACS_PCT_LT_HS',\n",
    "        'ACS_PCT_HS_GRADUATE',\n",
    "        'ACS_PCT_COLLEGE_ASSOCIATE_DGR',\n",
    "        'ACS_PCT_BACHELOR_DGR',\n",
    "        'ACS_PCT_GRADUATE_DGR',\n",
    "        'ACS_PCT_POSTHS_ED'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Train model with cross-validation to avoid overfitting\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10,  # Prevent overfitting\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Check model performance with cross-validation\n",
    "    cv_scores = cross_val_score(model, x_train_reg, y_train_reg, cv=5, scoring='r2')\n",
    "    print(f\"Cross-validation R² scores: {cv_scores}\")\n",
    "    print(f\"Mean R² score: {cv_scores.mean():.3f}\")\n",
    "    \n",
    "    model.fit(x_train_reg, y_train_reg)\n",
    "    y_pred_reg = model.predict(x_test_reg)\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    mape = mean_absolute_percentage_error(y_test_reg, y_pred_reg)\n",
    "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "    print(\"mae: \",mae)\n",
    "    print(\"mse: \",mse)\n",
    "    print(\"mape: \",mape)\n",
    "    print(\"r2: \",r2)\n",
    "\n",
    "    return model, feature_names\n",
    "\n",
    "\n",
    "def predict_with_model(model, feature_names, selected_career, selected_education_level):\n",
    "    \"\"\"\n",
    "    Use the trained model to predict suitability scores for each county based on\n",
    "    selected career and education level.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RandomForestRegressor model\n",
    "        feature_names: List of feature names used in training\n",
    "        selected_career: Career field selected by the user\n",
    "        selected_education_level: Education level selected by the user\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with counties and their predicted scores\n",
    "    \"\"\"\n",
    "    prediction_data = []\n",
    "    \n",
    "    # Extract education level weights for career adjustment\n",
    "    education_weight = {\n",
    "        'less_than_high_school': 0.5,\n",
    "        'high_school': 0.6,\n",
    "        'some_college/associates': 0.8,\n",
    "        'bachelors': 1.0,\n",
    "        'masters/doctorate': 1.1,\n",
    "        'postsecondary': 1.2\n",
    "    }.get(selected_education_level, 1.0)\n",
    "    \n",
    "    # Loop through each county\n",
    "    for _, county in clean_filtered_tennessee_gdf.iterrows():\n",
    "        # Build feature vector in the same order as during training\n",
    "        features = []\n",
    "        for f in feature_names:\n",
    "            features.append(county.get(f, 0))\n",
    "        \n",
    "\n",
    "        # Career field features\n",
    "        for career in career_field_features.keys():\n",
    "            columns = career_field_features[career]\n",
    "            if columns and columns[0] in county:\n",
    "                features.append(county[columns[0]])\n",
    "            else:\n",
    "                features.append(0)\n",
    "        \n",
    "        prediction_data.append({\n",
    "            'GEOID': county['GEOID'],\n",
    "            'COUNTY': county['COUNTY'],\n",
    "            'COUNTYFIPS': county['COUNTYFIPS'],\n",
    "            'features': features\n",
    "        })\n",
    "    \n",
    "    # Build prediction dataframe\n",
    "    prediction_df = pd.DataFrame(prediction_data)\n",
    "    \n",
    "    # Actually predict\n",
    "    features_matrix = np.vstack(prediction_df['features'])\n",
    "    base_preds = model.predict(features_matrix)\n",
    "    \n",
    "    # Apply career-specific and education-level adjustments\n",
    "    prediction_df['predicted_score'] = base_preds\n",
    "    \n",
    "    # Boost scores based on selected career field\n",
    "    if selected_career in career_field_features:\n",
    "        career_columns = career_field_features[selected_career]\n",
    "        \n",
    "        if career_columns and career_columns[0] in clean_filtered_tennessee_gdf.columns:\n",
    "            # Join to get the career-specific employment rate\n",
    "            career_data = clean_filtered_tennessee_gdf[['GEOID', career_columns[0]]]\n",
    "            prediction_df = pd.merge(prediction_df, career_data, on='GEOID')\n",
    "            \n",
    "            # Apply a career-specific boost\n",
    "            career_boost = prediction_df[career_columns[0]] / prediction_df[career_columns[0]].mean()\n",
    "            prediction_df['predicted_score'] = prediction_df['predicted_score'] * (0.7 + 0.3 * career_boost)\n",
    "    \n",
    "    # Apply education-level adjustment\n",
    "    edu_columns = education_levels.get(selected_education_level, [])\n",
    "    if edu_columns and edu_columns[0] in clean_filtered_tennessee_gdf.columns:\n",
    "        # Join to get the education match rate\n",
    "        edu_data = clean_filtered_tennessee_gdf[['COUNTYFIPS', edu_columns[0]]]\n",
    "        prediction_df = pd.merge(prediction_df, edu_data, on='COUNTYFIPS')\n",
    "        \n",
    "        # Apply an education-level adjustment\n",
    "        edu_match = prediction_df[edu_columns[0]] / prediction_df[edu_columns[0]].mean()\n",
    "        prediction_df['predicted_score'] = prediction_df['predicted_score'] * (0.8 + 0.2 * edu_match * education_weight)\n",
    "    \n",
    "    # Normalize scores to 0-100 range for interpretability\n",
    "    min_score = prediction_df['predicted_score'].min()\n",
    "    max_score = prediction_df['predicted_score'].max()\n",
    "    prediction_df['predicted_score'] = 100 * (prediction_df['predicted_score'] - min_score) / (max_score - min_score)\n",
    "    \n",
    "    return prediction_df.sort_values(by='predicted_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f301c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Train and use ML model\n",
    "    print(\"\\nTraining machine learning model...\")\n",
    "    model, feature_names = train_career_suitability_model()\n",
    "    \n",
    "    print(\"\\nAvailable career fields:\")\n",
    "    for i, career in enumerate(career_field_features.keys(), 1):\n",
    "        print(f\"{i}. {career.title()}\")\n",
    "    \n",
    "    # Get career field input\n",
    "    career_idx = int(input(\"\\nEnter the number for your desired career field: \")) - 1\n",
    "    career_field = list(career_field_features.keys())[career_idx]\n",
    "    \n",
    "    # Display available education levels\n",
    "    print(\"\\nAvailable education levels:\")\n",
    "    for i, edu_level in enumerate(education_levels.keys(), 1):\n",
    "        print(f\"{i}. {edu_level.replace('_', ' ').title()}\")\n",
    "    \n",
    "    # Get education level input\n",
    "    edu_idx = int(input(\"\\nEnter the number for your education level: \")) - 1\n",
    "    education_level = list(education_levels.keys())[edu_idx]\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = predict_with_model(model, feature_names, career_field, education_level)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Display top 10 counties\n",
    "    print(\"\\nTop 10 recommended counties for your career (ML predictions):\")\n",
    "    top_counties = predictions.head(10)\n",
    "    display(top_counties)\n",
    "    \n",
    "    \n",
    "    # Create a copy of the complete Tennessee GeoDataFrame\n",
    "    tn_plot_gdf = clean_filtered_tennessee_gdf.copy()\n",
    "\n",
    "    print(\"clean_filtered_tennessee_gdf shape:\", clean_filtered_tennessee_gdf.shape)\n",
    "    print(\"tn_plot_gdf shape:\", tn_plot_gdf.shape)\n",
    "    print(\"predictions shape:\", predictions.shape)\n",
    "    print(predictions.head())\n",
    "    \n",
    "\n",
    "    # Merge the predictions with the complete Tennessee GeoDataFrame\n",
    "    tn_plot_gdf = pd.merge(\n",
    "        tn_plot_gdf,\n",
    "        predictions[['GEOID', 'predicted_score']],\n",
    "        on=['GEOID'],\n",
    "        how='left'  # Important: use left join to keep all counties\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Fill NaN values for counties without predictions\n",
    "    #tn_plot_gdf['predicted_score'] = tn_plot_gdf['predicted_score'].fillna(-1)\n",
    "    print(\"NAN values still: \", tn_plot_gdf['predicted_score'].isna().sum())\n",
    "    display(tn_plot_gdf)\n",
    "\n",
    "\n",
    "    # Plotting the counties with the predicted scores\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    tn_plot_gdf.plot(column='predicted_score', cmap='viridis', legend=True, ax=ax)\n",
    "    plt.title(f'Career Suitability Scores for {career_field.title()} with {education_level.title()} by County')\n",
    "    plt.axis('off')  # Hide axis for clean visualization\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91cf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
